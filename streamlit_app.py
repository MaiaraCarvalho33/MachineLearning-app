import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np  # 


# Carregar os dados
df = pd.read_csv("dados.csv")
df["RDS_clean"] = df["RDS"].str.replace("%", "").astype(float)

# ================================
# P√°gina 1 ‚Äì Defini√ß√£o do Problema
# ================================
def pagina_definicao_problema():
    st.markdown("# üß© Defini√ß√£o do Problema")

    st.markdown("## Contextualiza√ß√£o do Desafio")
    st.write("""
    No cen√°rio financeiro atual, a concess√£o de cr√©dito √© uma atividade essencial para bancos e institui√ß√µes financeiras, 
    mas tamb√©m acarreta riscos significativos. A inadimpl√™ncia de clientes pode gerar perdas substanciais, impactando a 
    lucratividade e a estabilidade das institui√ß√µes. A an√°lise de cr√©dito tradicional, muitas vezes baseada em crit√©rios 
    subjetivos e informa√ß√µes limitadas, pode n√£o ser suficiente para identificar com precis√£o o perfil de risco de cada solicitante.

    O dataset `dados.csv` cont√©m informa√ß√µes sobre clientes de uma institui√ß√£o financeira, incluindo seu status 
    como "bom pagador" ou "mau pagador", al√©m de diversas vari√°veis como valor de empr√©stimo, finalidade, tempo de emprego, 
    indicadores de cr√©dito e limites de cr√©dito. 
    """)

    st.markdown("## Objetivo do Modelo")
    st.write("""
    Desenvolver um modelo de machine learning capaz de prever se um cliente ser√° um **bom pagador** ou **mau pagador** 
    com base nos dados dispon√≠veis no momento da an√°lise.
    """)

    st.markdown("## Relev√¢ncia para o Neg√≥cio")
    st.markdown("""
    - **Minimiza√ß√£o de perdas por inadimpl√™ncia**
    - **Otimiza√ß√£o da concess√£o de cr√©dito**
    - **Melhoria na gest√£o de risco**
    - **Aumento da lucratividade**
    - **Identifica√ß√£o de oportunidades**
    - **Decis√µes orientadas por dados**
    """)

# =============================================
# P√°gina 2 ‚Äì An√°lise Explorat√≥ria e Insights
# =============================================
def pagina_eda():
    st.markdown("# üìä An√°lise Explorat√≥ria dos Dados (EDA) e Insights")

    st.markdown("## üßæ Vis√£o Geral dos Dados")
    st.dataframe(df.head())

    # =========================
    st.markdown("## üéØ Distribui√ß√£o da Vari√°vel Alvo ‚Äì Cliente")
    fig1, ax1 = plt.subplots()
    sns.countplot(x="Cliente", data=df, ax=ax1)
    ax1.set_title("Distribui√ß√£o de Bons e Maus Pagadores")
    st.pyplot(fig1)

    st.markdown("""
    üîç **Observa√ß√£o:**  
    O gr√°fico mostra que a maioria dos clientes √© classificada como **bom pagador**, enquanto os **maus pagadores** s√£o minoria.  
    Esse desbalanceamento pode levar o modelo a priorizar a classe majorit√°ria e **ignorar os maus pagadores**, que s√£o os mais importantes a identificar.
    """)

    # =========================
    st.markdown("## üìà Histogramas com KDE por Vari√°vel Num√©rica")
    variaveis_hist = ['Empr√©stimo', 'ValorDoBem', 'TempoEmprego', 'TempoCliente', 'LC-Recente', 'LC-Atual', 'RDS_clean']

    for col in variaveis_hist:
        fig, ax = plt.subplots()
        sns.histplot(data=df, x=col, hue="Cliente", kde=True, ax=ax)
        ax.set_title(f"Distribui√ß√£o de {col} por tipo de Cliente")
        st.pyplot(fig)

        # Texto explicativo para cada vari√°vel
        if col == "TempoEmprego":
            st.markdown("üîç **TempoEmprego:** Bons pagadores tendem a ter mais tempo de emprego, indicando maior estabilidade.")
        elif col == "TempoCliente":
            st.markdown("üîç **TempoCliente:** Clientes mais antigos tendem a ser mais confi√°veis.")
        elif col == "RDS_clean":
            st.markdown("üîç **RDS_clean:** Score de risco ‚Äî valores mais altos aparecem entre os maus pagadores.")
        elif col == "LC-Recente":
            st.markdown("üîç **LC-Recente:** Maus pagadores s√£o mais comuns entre clientes com limite de cr√©dito recente muito baixo ou nulo.")
        elif col == "LC-Atual":
            st.markdown("üîç **LC-Atual:** Bons pagadores concentram-se em faixas de limite de cr√©dito maiores.")
        else:
            st.markdown(f"üîç **{col}:** Distribui√ß√£o assim√©trica, com valores altos concentrados nos bons pagadores.")

    # =========================
    st.markdown("## üì¶ Boxplots por Classe ‚Äì Compara√ß√£o de Distribui√ß√µes")
    for col in variaveis_hist:
        fig, ax = plt.subplots()
        sns.boxplot(x="Cliente", y=col, data=df, ax=ax)
        ax.set_title(f"{col} por tipo de Cliente")
        st.pyplot(fig)

    st.markdown("""
    üîç **Interpreta√ß√£o dos Boxplots:**
    - As medianas de **TempoEmprego** e **TempoCliente** s√£o maiores para bons pagadores.
    - A vari√°vel **RDS_clean** tende a ser mais alta entre maus pagadores.
    - **LC-Atual** e **LC-Recente** tamb√©m diferenciam sutilmente os grupos.
    - Algumas vari√°veis como **Empr√©stimo** e **ValorDoBem** t√™m muitos outliers, o que pode distorcer m√©dias e dispers√µes.
    """)

    # =========================
    st.markdown("## üîó Matriz de Correla√ß√£o entre Vari√°veis Num√©ricas")
    fig_corr, ax_corr = plt.subplots(figsize=(10, 6))
    sns.heatmap(df[variaveis_hist].corr(), annot=True, cmap="coolwarm", fmt=".2f", ax=ax_corr)
    ax_corr.set_title("Correla√ß√£o entre vari√°veis num√©ricas")
    st.pyplot(fig_corr)

    st.markdown("""
    üîç **Matriz de Correla√ß√£o ‚Äì Destaques:**
    - Correla√ß√£o **forte** entre **ValorDoBem** e **Empr√©stimo**.
    - Correla√ß√£o **moderada** entre **TempoCliente** e **TempoEmprego**.
    - **RDS_clean** n√£o √© fortemente correlacionada com outras vari√°veis ‚Äî pode ser uma vari√°vel **independente e poderosa**.
    """)

    # =========================
    st.markdown("## üìå Principais Descobertas")
    st.markdown("""
    - **TempoEmprego**, **TempoCliente** e **RDS_clean** s√£o bons candidatos para predi√ß√£o.
    - **LC-Atual** e **LC-Recente** oferecem informa√ß√µes √∫teis sobre a avalia√ß√£o da institui√ß√£o.
    - Algumas vari√°veis t√™m distribui√ß√£o assim√©trica e outliers que podem interferir nos modelos.
    - A separa√ß√£o entre as classes ocorre com mais clareza em algumas vari√°veis do que em outras.
    """)

    # =========================
    st.markdown("## üß† Considera√ß√µes Finais para Modelagem")
    st.markdown("""
    - ‚ö†Ô∏è **Desbalanceamento de classes** deve ser tratado com SMOTE ou `class_weight`.
    - üßπ Tratar valores ausentes em vari√°veis como **TempoEmprego** e **RDS**.
    - üî§ Realizar One-Hot Encoding em vari√°veis como **Finalidade** e **Emprego**.
    - üßÆ Criar vari√°veis derivadas como:
        - `TotalHistoricoRuim = Negativos + Atrasos`
        - `RazaoEmprestimoValorBem = Empr√©stimo / ValorDoBem`
    - üö´ Tratar **outliers** extremos para evitar distor√ß√µes em algoritmos baseados em m√©dia.
    """)
###########pre
import numpy as np  # Certifique-se de ter isso no topo do arquivo

def pagina_preprocessamento():
    st.markdown("# üßº Pr√©-processamento dos Dados")

    # ========================
    st.markdown("## 1. Tratamento de Valores Ausentes")
    st.markdown("""
    - **TempoEmprego** e **RDS** possuem valores ausentes.
    - Estrat√©gia aplicada:
        - **TempoEmprego**: substitu√≠do pela mediana da vari√°vel.
        - **RDS**: convertido de string para n√∫mero (`RDS_clean`), depois preenchido com a **mediana por tipo de cliente**.
    """)

    fig, axs = plt.subplots(1, 2, figsize=(12, 4))
    sns.histplot(data=df, x="TempoEmprego", kde=True, ax=axs[0])
    axs[0].set_title("Distribui√ß√£o de TempoEmprego")

    sns.histplot(data=df, x="RDS_clean", kde=True, ax=axs[1])
    axs[1].set_title("Distribui√ß√£o de RDS_clean (limpo)")
    st.pyplot(fig)

    # ========================
    st.markdown("## 2. Tratamento de Outliers")
    st.markdown("""
    - Vari√°veis como **Empr√©stimo** e **ValorDoBem** apresentaram valores extremos.
    - Estrat√©gia recomendada:
        - Aplicar **capping** usando o percentil 1% e 99%, ou
        - Transforma√ß√µes como `log1p` para reduzir assimetrias.
    """)

    for col in ["Empr√©stimo", "ValorDoBem"]:
        fig, axs = plt.subplots(1, 2, figsize=(12, 4))
        sns.histplot(data=df, x=col, hue="Cliente", kde=True, ax=axs[0])
        axs[0].set_title(f"{col} - Original")

        sns.histplot(np.log1p(df[col]), ax=axs[1], bins=30, kde=True)
        axs[1].set_title(f"{col} - log1p Transformado")
        st.pyplot(fig)

    # ========================
    st.markdown("## 3. Codifica√ß√£o de Vari√°veis Categ√≥ricas")
    st.markdown("""
    - Vari√°veis como **Emprego** e **Finalidade** s√£o categ√≥ricas.
    - Estrat√©gia aplicada:
        - **One-Hot Encoding**: cria uma coluna bin√°ria para cada categoria.
        - Alternativa para √°rvores de decis√£o: **Label Encoding** ou deixar como string (algoritmos lidam bem).
    """)

    st.markdown("Exemplo de distribui√ß√£o de valores categ√≥ricos:")
    for col in ["Emprego", "Finalidade"]:
        st.markdown(f"### üìä {col}")
        fig, ax = plt.subplots()
        sns.countplot(data=df, x=col, order=df[col].value_counts().index, ax=ax)
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)
        st.pyplot(fig)

    # ========================
    st.markdown("## 4. Normaliza√ß√£o de Vari√°veis Cont√≠nuas")
    st.markdown("""
    - Para algoritmos sens√≠veis √† escala (ex: KNN, Regress√£o Log√≠stica), foi aplicada:
        - **Padroniza√ß√£o Z-score** (m√©dia 0, desvio padr√£o 1), ou
        - **Min-Max Scaling** (valores entre 0 e 1).
    """)

    st.markdown("üìå Exemplos de vari√°veis antes da normaliza√ß√£o:")
    cols_norm = ["TempoCliente", "LC-Atual", "LC-Recente"]
    fig, ax = plt.subplots()
    df[cols_norm].boxplot(ax=ax)
    ax.set_title("Boxplot das vari√°veis cont√≠nuas")
    st.pyplot(fig)

    # ========================
    st.markdown("## 5. Engenharia de Vari√°veis")
    st.markdown("""
    Foram criadas novas vari√°veis com base em conhecimento de dom√≠nio:

    - `RazaoEmprestimoValorBem = Empr√©stimo / ValorDoBem`
        - Indica o quanto do bem est√° sendo financiado.

    - `TotalHistoricoRuim = Negativos + Atrasos`
        - Resume o hist√≥rico de inadimpl√™ncia em uma s√≥ vari√°vel.
    """)

    # Criar as vari√°veis
    df["RazaoEmprestimoValorBem"] = df["Empr√©stimo"] / df["ValorDoBem"]
    df["TotalHistoricoRuim"] = df["Negativos"] + df["Atrasos"]

    for new_col in ["RazaoEmprestimoValorBem", "TotalHistoricoRuim"]:
        fig, axs = plt.subplots(1, 2, figsize=(12, 4))
        sns.histplot(data=df, x=new_col, hue="Cliente", kde=True, ax=axs[0])
        axs[0].set_title(f"{new_col} - Original")

        sns.histplot(np.log1p(df[new_col]), ax=axs[1], bins=30, kde=True)
        axs[1].set_title(f"{new_col} - log1p Transformado")
        st.pyplot(fig)

    # ========================
    st.markdown("## 6. Balanceamento da Vari√°vel Alvo")
    st.markdown("""
    O conjunto de dados √© desbalanceado (muito mais bons pagadores que maus).

    Estrat√©gias sugeridas:
    - **SMOTE**: t√©cnica de oversampling sint√©tico para a classe minorit√°ria.
    - **Class Weights**: ajuste do peso da classe minorit√°ria no algoritmo.
    """)

    fig, ax = plt.subplots()
    sns.countplot(x="Cliente", data=df, ax=ax)
    ax.set_title("Distribui√ß√£o da vari√°vel alvo (Cliente)")
    st.pyplot(fig)

    # ========================
    st.markdown("## 7. Divis√£o dos Dados")
    st.markdown("""
    Os dados foram divididos em:

    - **Treinamento** (80% dos dados)
    - **Teste** (20% restantes)

    Mantendo a propor√ß√£o entre bons e maus pagadores (estratifica√ß√£o).
    """)

    from sklearn.model_selection import train_test_split
    X = df.drop("Cliente", axis=1)
    y = df["Cliente"]
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )

    st.success("‚úÖ Divis√£o realizada com sucesso!")
    st.markdown(f"- Treinamento: {X_train.shape[0]} registros")
    st.markdown(f"- Teste: {X_test.shape[0]} registros")
####
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (
    classification_report, confusion_matrix,
    roc_curve, auc, precision_recall_curve
)
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
import streamlit as st

def pagina_modelagem_avaliacao():
    st.markdown("# ü§ñ Modelagem e Avalia√ß√£o")

    # ===================================
    # 1. Prepara√ß√£o dos Dados
    # ===================================
    st.markdown("## 1. Prepara√ß√£o dos Dados")
    df_modelo = df.copy()

    for col in df_modelo.select_dtypes(include='number').columns:
        df_modelo[col] = df_modelo[col].fillna(df_modelo[col].median())

    for col in df_modelo.select_dtypes(include='object').columns:
        df_modelo[col] = df_modelo[col].fillna(df_modelo[col].mode()[0])

    le = LabelEncoder()
    df_modelo["Cliente"] = le.fit_transform(df_modelo["Cliente"])  # bom pagador = 1, mau = 0

    df_modelo = pd.get_dummies(df_modelo, drop_first=True)

    X = df_modelo.drop("Cliente", axis=1)
    y = df_modelo["Cliente"]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y, random_state=42
    )

    st.success("‚úÖ Dados preparados com sucesso!")

    # ===================================
    # 2. Treinamento e Avalia√ß√£o
    # ===================================
    st.markdown("## 2. Treinamento e Avalia√ß√£o dos Modelos")

    modelos = {
        "Regress√£o Log√≠stica": LogisticRegression(max_iter=1000),
        "√Årvore de Decis√£o": DecisionTreeClassifier(),
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42)
    }

    resultados_modelos = []

    for nome, modelo in modelos.items():
        st.markdown(f"### üîç {nome}")
        modelo.fit(X_train, y_train)
        y_pred = modelo.predict(X_test)
        y_prob = modelo.predict_proba(X_test)[:, 1]

        # Matriz de Confus√£o
        fig_cm, ax_cm = plt.subplots()
        sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Blues", ax=ax_cm)
        ax_cm.set_title(f"Matriz de Confus√£o - {nome}")
        ax_cm.set_xlabel("Predito")
        ax_cm.set_ylabel("Real")
        st.pyplot(fig_cm)

        # Relat√≥rio
        st.markdown("**Relat√≥rio de Classifica√ß√£o:**")
        st.text(classification_report(y_test, y_pred, target_names=["mau pagador", "bom pagador"]))

        report_dict = classification_report(y_test, y_pred, output_dict=True)
        precision = report_dict['0']['precision']  # mau pagador = 0
        recall = report_dict['0']['recall']
        f1 = report_dict['0']['f1-score']
        acc = report_dict['accuracy']

        # Curva ROC
        fpr, tpr, _ = roc_curve(y_test, y_prob)
        roc_auc = auc(fpr, tpr)
        fig_roc, ax_roc = plt.subplots()
        ax_roc.plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')
        ax_roc.plot([0, 1], [0, 1], 'k--')
        ax_roc.set_xlabel("Falso Positivo")
        ax_roc.set_ylabel("Verdadeiro Positivo")
        ax_roc.set_title(f"Curva ROC - {nome}")
        ax_roc.legend()
        st.pyplot(fig_roc)

        # Curva Precision-Recall
        precisions, recalls, _ = precision_recall_curve(y_test, y_prob)
        fig_pr, ax_pr = plt.subplots()
        ax_pr.plot(recalls, precisions)
        ax_pr.set_xlabel("Recall")
        ax_pr.set_ylabel("Precision")
        ax_pr.set_title(f"Curva Precision-Recall - {nome}")
        st.pyplot(fig_pr)

        # Valida√ß√£o Cruzada
        scores = cross_val_score(modelo, X, y, cv=5, scoring='accuracy')
        st.markdown(f"**Valida√ß√£o Cruzada (5-fold):** {np.round(scores, 3)}")
        st.markdown(f"**Acur√°cia M√©dia:** {scores.mean():.4f}")

        # Guardar resultados
        resultados_modelos.append({
            "Modelo": nome,
            "f1_mau_pagador": f1,
            "Recall_mau": recall,
            "Precision_mau": precision,
            "Acur√°cia teste": acc,
            "Acur√°cia Val. Cruzada": scores.mean()
        })

        st.markdown("---")

 

def pagina_relatorio_final():
    st.markdown("# üìà Relat√≥rio Final do Projeto")

    # =====================
    # Comparativo Final dos Modelos (dados fixos)
    # =====================
    st.markdown("## üìä Comparativo Final dos Modelos")

    dados = {
        "Modelo": ["Random Forest", "Regress√£o Log√≠stica", "√Årvore de Decis√£o"],
        "F1_mau_pagador": [0.947, 0.926, 0.913],
        "Recall_mau": [0.991, 0.966, 0.926],
        "Precision_mau": [0.906, 0.889, 0.900],
        "Acur√°cia Teste": [0.909, 0.874, 0.856],
        "Acur√°cia Val. Cruzada": [0.896, 0.859, 0.862]
    }

    comparativo = pd.DataFrame(dados)
    st.dataframe(comparativo.style.format(precision=3), use_container_width=True)

    # =====================
    # An√°lise Comparativa
    # =====================
    st.markdown("## üìå An√°lise Comparativa dos Modelos")
    st.write("""
    O modelo **Random Forest** se destacou como o melhor para prever maus pagadores, com base nas seguintes evid√™ncias:

    - **F1-Score mais alto (0.947)** para a classe de interesse, indicando o melhor equil√≠brio entre precis√£o e recall.
    - **Recall de 0.991**, ou seja, quase todos os inadimplentes foram identificados corretamente.
    - **Precision de 0.906**, o que significa que, quando o modelo indica que algu√©m √© inadimplente, geralmente est√° certo.
    - **Acur√°cia de teste (0.909)** e **valida√ß√£o cruzada (0.896)** mostram que o modelo √© robusto e consistente, evitando overfitting.
    - **AUC = 0.96**, evidenciado pela curva ROC, confirma o excelente desempenho na separa√ß√£o entre classes.

    J√° os outros modelos apresentaram desempenho inferior:

    - **Regress√£o Log√≠stica** teve bom recall (0.966), mas menor precis√£o e acur√°cia geral. Seu **AUC foi 0.85**, indicando desempenho razo√°vel, mas inferior ao Random Forest.
    - **√Årvore de Decis√£o** teve o pior desempenho, com menor estabilidade e **AUC de apenas 0.74**, o que mostra dificuldade em distinguir corretamente os inadimplentes dos bons pagadores.
    """)

    st.markdown("### üîç Conclus√£o")
    st.write("""
    Com base nos resultados, o **Random Forest** √© o modelo mais indicado para o problema, por garantir:

    - Maior identifica√ß√£o de inadimplentes (**recall alto**)
    - Menos falsos positivos e negativos (**alta precis√£o**)
    - Melhor desempenho geral nas m√©tricas cr√≠ticas do neg√≥cio
    - Maior √°rea sob a curva ROC (**AUC = 0.96**), indicando excelente separabilidade

    Esse modelo contribui para **minimizar riscos de concess√£o de cr√©dito indevido** e **otimizar a rentabilidade da institui√ß√£o**.
    """)
# ========================
# Fun√ß√£o da nova p√°gina - Sobre o Projeto
# ========================
def pagina_sobre():
    st.markdown("# üìò Sobre o Projeto")

    st.markdown("## üìå Contexto")
    st.write("""
    Este projeto tem como objetivo utilizar t√©cnicas de **Machine Learning** para prever se um cliente ser√° **bom** ou **mau pagador**, 
    com base em um conjunto de dados fornecido por uma institui√ß√£o financeira.
    """)

    st.markdown("## ‚öôÔ∏è Ferramentas Utilizadas")
    st.markdown("""
    - `Python` e `Streamlit` para o desenvolvimento do app interativo
    - `Pandas` e `NumPy` para manipula√ß√£o de dados
    - `Seaborn` e `Matplotlib` para visualiza√ß√£o
    - `Scikit-learn` para modelagem estat√≠stica
    """)

    st.markdown("## üéØ Foco da Predi√ß√£o")
    st.write("""
    A vari√°vel-alvo √© o status do cliente (bom ou mau pagador). A principal m√©trica de avalia√ß√£o √© o **F1-score** da classe 'mau pagador',
    devido √† sua import√¢ncia para o neg√≥cio.
    """)

    st.markdown("## üë©‚Äçüíª Autoria")
    st.write("""
    Projeto desenvolvido por **Maiara Carvalho**
    """)


# =============================================
# Navega√ß√£o entre p√°ginas
# =============================================
pagina = st.sidebar.radio("Selecione a p√°gina:", [
    "Defini√ß√£o do Problema", 
    "An√°lise Explorat√≥ria (EDA)",
    "Pr√©-processamento dos Dados",
    "Modelagem e Avalia√ß√£o",
    "Relat√≥rio Final",
    "Sobre o Projeto"
])

if pagina == "Defini√ß√£o do Problema":
    pagina_definicao_problema()

elif pagina == "An√°lise Explorat√≥ria (EDA)":
    pagina_eda()

elif pagina == "Pr√©-processamento dos Dados":
    pagina_preprocessamento()

elif pagina == "Modelagem e Avalia√ß√£o":
    resultados_modelos = pagina_modelagem_avaliacao()

elif pagina == "Relat√≥rio Final":
    pagina_relatorio_final()

elif pagina == "Sobre o Projeto":
    pagina_sobre()
